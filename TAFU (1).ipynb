{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrgDTT8HFQUW"
      },
      "source": [
        "## CV ga oid bazi misollar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jafo6bOMIGsN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = cv2.imread(\"/content/fil.jpg\")\n",
        "if img is None:\n",
        "    raise ValueError(\"xatolik\")\n",
        "\n",
        "B, G, R = cv2.split(img)\n",
        "\n",
        "zeros = np.zeros_like(B)\n",
        "\n",
        "blue_img  = cv2.merge([B, zeros, zeros])\n",
        "green_img = cv2.merge([zeros, G, zeros])\n",
        "red_img   = cv2.merge([zeros, zeros, R])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(cv2.cvtColor(blue_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Blue Channel\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(cv2.cvtColor(green_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Green Channel\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cv2.cvtColor(red_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Red Channel\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZAQN-cTyiDW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eOf2t-d1Mm5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"/content/fil.jpg\")\n",
        "\n",
        "cv2_imshow(img)\n",
        "\n",
        "print(\"Image shape (H, W, C):\", img.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJpQ7jnK1Mui"
      },
      "outputs": [],
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "print(\"Gray shape:\", gray.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e3eSOoE1M0O"
      },
      "outputs": [],
      "source": [
        "resized = cv2.resize(img, (300, 100))\n",
        "cv2_imshow(resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwqGFMrR1M47"
      },
      "outputs": [],
      "source": [
        "crop = img[50:250, 50:200]  # y1:y2, x1:x2\n",
        "cv2_imshow(crop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw83mDx-2Vo9"
      },
      "outputs": [],
      "source": [
        "blur = cv2.GaussianBlur(img, (15, 15), 0)\n",
        "cv2_imshow(blur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TqmVb572VvF"
      },
      "outputs": [],
      "source": [
        "edges = cv2.Canny(img, 100, 200)\n",
        "cv2_imshow(edges)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzT0GCqm2V06"
      },
      "outputs": [],
      "source": [
        "ret, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "cv2_imshow(thresh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nTmiBDu2V6A"
      },
      "outputs": [],
      "source": [
        "draw = img.copy()\n",
        "\n",
        "cv2.rectangle(draw, (50, 50), (200, 200), (0, 255, 0), 3)\n",
        "cv2.circle(draw, (250, 250), 50, (255, 0, 0), 3)\n",
        "cv2.putText(draw, \"CV!\", (50, 300),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "\n",
        "cv2_imshow(draw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzkzZbCt2V_q"
      },
      "outputs": [],
      "source": [
        "h, w = img.shape[:2]\n",
        "center = (w//2, h//2)\n",
        "matrix = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
        "rotated = cv2.warpAffine(img, matrix, (w, h))\n",
        "cv2_imshow(rotated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPQ6YGwA1NKy"
      },
      "outputs": [],
      "source": [
        "flip_h = cv2.flip(img, 1)   # horizontal\n",
        "flip_v = cv2.flip(img, 0)   # vertical\n",
        "cv2_imshow(flip_h)\n",
        "cv2_imshow(flip_v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvF4g1Zw3tCk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILZV8lNf3tIz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I2QiEYf3tON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHdoSP6D3tdr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoyWSyS0pbS7"
      },
      "source": [
        "# Kernel- (fiilterlar) lar\n",
        "\n",
        "## 1. Smoothing\n",
        "\n",
        "###  // Model structure  \\\\\\\\\n",
        "\n",
        "##### - We define a simple CNN model with one convolution layer.\n",
        "##### - A 3x3 averaging kernel(filter) is applied to produce the smoothing effect, which reduces high-frequency noise by averaging pixel values in the kernel‚Äôs neighborhood.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBQF3Mvspm3X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "image_path = \"/content/fil.jpg\"\n",
        "image = Image.open(image_path)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "input_image = transform(image).unsqueeze(0)\n",
        "\n",
        "\n",
        "class SmoothingCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SmoothingCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        smoothing_kernel = np.array([[-1, 1, -1],\n",
        "                                     [-1, -10, -1],\n",
        "                                     [-1, 1, -1]]) / 9.0\n",
        "\n",
        "        self.conv1.weight.data = torch.tensor(smoothing_kernel, dtype=torch.float32).repeat(1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv1(x)\n",
        "model = SmoothingCNN()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "with torch.no_grad():\n",
        "    smoothed_image = model(input_image).squeeze(0).squeeze(0).numpy()\n",
        "smoothed_image_uint8 = (smoothed_image * 255).astype(np.uint8)\n",
        "\n",
        "rasm_joylashuvi = '/content/filterli_rasm.jpg'\n",
        "\n",
        "cv2.imwrite(rasm_joylashuvi , smoothed_image_uint8)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(np.transpose(input_image.squeeze(0).numpy(), (1, 2, 0)))\n",
        "plt.title(\"Haqiqiy rasm\")\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(smoothed_image, cmap=\"gray\")\n",
        "plt.title(\"Filterlangan rasm\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Filterlangan rasmn saqlandi: {rasm_joylashuvi}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncZJHolUydt9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV6VHBp70BHB"
      },
      "source": [
        "# 2. Sharpening kernel application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3tYDXqXyyQv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sharpen_image(image_path, output_path):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Yuklashda xatolik: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # O'tkirlashtiruvchi filter (kernal)\n",
        "    sharpening_kernel = np.array([[0, -1, 0],\n",
        "                                  [-1, 5, -1],\n",
        "                                  [0, -1, 0]])\n",
        "\n",
        "    sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)\n",
        "    cv2.imwrite(output_path, sharpened_image)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Haqiqiy rasm\")\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"O'tkirlashgan rasm\")\n",
        "    plt.imshow(cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "input_image_path = '/content/fil.jpg'\n",
        "output_image_path = \"/content/elephant_o'tkirlashgani.jpg\"\n",
        "\n",
        "sharpen_image(input_image_path, output_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOpNT_ex2xAT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoQ7oSH42zWV"
      },
      "source": [
        "# 3. Edge Detection based kernels\n",
        "\n",
        "\n",
        "## 3.1. Sobel\n",
        "\n",
        "#### Sobel operator is a discrete differentiation operator that computes an approximation of the gradient of the image intensity function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lzA8oVf2xDG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def apply_kernel(input_image, kernel):\n",
        "    kernel_tensor = torch.tensor(kernel, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "    model = nn.Conv2d(1, 1, kernel_size=kernel_tensor.shape[2:], stride=1, padding=1, bias=False)\n",
        "    model.weight.data = kernel_tensor\n",
        "    output = model(input_image)\n",
        "    return output.squeeze(0).squeeze(0).detach().numpy()\n",
        "\n",
        "image_path = \"/content/fil.jpg\"\n",
        "image = Image.open(image_path).convert(\"L\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "input_image = transform(image).unsqueeze(0)\n",
        "\n",
        "# Sobel kernel\n",
        "sobel_x = np.array([[1, 0, -1],\n",
        "                    [2, 0, -2],\n",
        "                    [1, 0, -1]])\n",
        "\n",
        "sobel_y = np.array([[1, 2, 1],\n",
        "                    [0, 0, 0],\n",
        "                    [-1, -2, -1]])\n",
        "\n",
        "sobel_edge_x = apply_kernel(input_image, sobel_x)\n",
        "sobel_edge_y = apply_kernel(input_image, sobel_y)\n",
        "sobel_edges = np.sqrt(sobel_edge_x**2 + sobel_edge_y**2)\n",
        "\n",
        "cv2.imwrite('/content/sobel_edges.jpg', (sobel_edges * 255).astype(np.uint8))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(np.transpose(input_image.squeeze(0).numpy(), (1, 2, 0)), cmap='gray')\n",
        "plt.title(\"Haqiqiy rasm\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(sobel_edge_x, cmap='gray')\n",
        "plt.title(\"Sobel Edge X\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(sobel_edge_y, cmap='gray')\n",
        "plt.title('Sobel Edge Y')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "# print(\"/content/sobel_edges.jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maKUJTsN2xFr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQXdjO5L3Zbi"
      },
      "source": [
        "# 4.2. Prewitt Edge Detection\n",
        "\n",
        "\n",
        "#### Prewitt operator is similar to the Sobel operator but uses different kernels to compute gradients\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCaboXcK2xNS"
      },
      "outputs": [],
      "source": [
        "# Prewitt kernels\n",
        "prewitt_x = np.array([[1, 0, -1],\n",
        "                      [1, 0, -1],\n",
        "                      [1, 0, -1]])\n",
        "\n",
        "prewitt_y = np.array([[1, 1, 1],\n",
        "                      [0, 0, 0],\n",
        "                      [-1, -1, -1]])\n",
        "\n",
        "prewitt_edge_x = apply_kernel(input_image, prewitt_x)\n",
        "prewitt_edge_y = apply_kernel(input_image, prewitt_y)\n",
        "\n",
        "prewitt_edges = np.sqrt(prewitt_edge_x**2 + prewitt_edge_y**2)\n",
        "\n",
        "cv2.imwrite('/content/fil.jpg', (prewitt_edges * 255).astype(np.uint8))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(np.transpose(input_image.squeeze(0).numpy(), (1, 2, 0)))\n",
        "plt.title(\"Orginal rasm\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(prewitt_edge_x, cmap='gray')\n",
        "plt.title(\"Prewitt Edge X\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(prewitt_edge_y, cmap='gray')\n",
        "plt.title(\"Prewitt Edge Y \")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(prewitt_edges, cmap='gray')\n",
        "plt.title(\"Prewitt Edges\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbclihkz2xSO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkUdNVQV2xUn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ0v_Hen3yz9"
      },
      "source": [
        "# **Roberts Edge Detection**\n",
        "\n",
        "#### Roberts Cross operator uses a pair of 2x2 convolution kernels to approximate the gradient of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMXoc9vg2xW-"
      },
      "outputs": [],
      "source": [
        "# Roberts kernels\n",
        "roberts_x = np.array([[1, 0],\n",
        "                      [0, -1]])\n",
        "\n",
        "roberts_y = np.array([[0, 1],\n",
        "                      [-1, 0]])\n",
        "\n",
        "roberts_edge_x = apply_kernel(input_image, roberts_x)\n",
        "roberts_edge_y = apply_kernel(input_image, roberts_y)\n",
        "\n",
        "roberts_edges = np.sqrt(roberts_edge_x**2 + roberts_edge_y**2)\n",
        "\n",
        "cv2.imwrite('/content/elephantv2.jpg', (roberts_edges * 255).astype(np.uint8))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(np.transpose(input_image.squeeze(0).numpy(), (1, 2, 0)))\n",
        "plt.title(\"Original rasm\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(roberts_edge_x, cmap='gray')\n",
        "plt.title(\"Roberts Edge X\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(roberts_edge_x, cmap='gray')\n",
        "plt.title(\"Roberts Edge Y\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(roberts_edges, cmap='gray')\n",
        "plt.title(\"Roberts Edges\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFurLzpF2xZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6eM4l7g2xcC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwwqBXwj3-8f"
      },
      "source": [
        "# **Canny Edge Detection**\n",
        "\n",
        "#### Canny edge detection is a multi-stage algorithm that detects a wide range of edges in images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQO0sfgz2xey"
      },
      "outputs": [],
      "source": [
        "# Canny Edge Detection using OpenCV\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = \"/content/elephantv2.jpg\"\n",
        "image = Image.open(image_path).convert(\"L\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "input_image = transform(image).squeeze(0).numpy()\n",
        "\n",
        "input_image_uint8 = (input_image * 255).astype(np.uint8)\n",
        "edges_canny = cv2.Canny(input_image_uint8, 100, 200)\n",
        "\n",
        "cv2.imwrite('/content/canny_edges.jpg', edges_canny)\n",
        "\n",
        "# Display results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "plt.title(\"Original rasm\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(edges_canny, cmap='gray')\n",
        "plt.title(\"Canny Edges\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHrEsa2b2xhV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-34SRmd24KRC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avwOp0d14f-q"
      },
      "source": [
        "# **Summary**\n",
        "\n",
        "---\n",
        "\n",
        "*   **Sobel:** Measures gradients in both the x and y directions\n",
        "\n",
        "*   **Prewitt:** Similar to Sobel but with different weights\n",
        "*   **Roberts:** Focuses on a 2x2 kernel for edge detection, giving sharper results\n",
        "\n",
        "*   **Canny:** A multi-step process that involves Gaussian smoothing and hysteresis thresholding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQUTJ4hw4Kf_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5k6IWW1JVkx"
      },
      "source": [
        "# Convolution with Different Kernel Sizes\n",
        "\n",
        "### In this example, we'll create a simple grayscale image and apply convolutional filters with different kernel sizes\n",
        "(ex: 3√ó3, 5√ó5, and 7√ó7)\n",
        "### to see how each size influences the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYuDy1bOI2eQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image_path = \"/content/elephantv2.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# kernelni (filterni aniqlash) 3x3 and 5x5 kernels\n",
        "kernel_3x3 = np.array([[1, 0, -1],\n",
        "                       [1, 0, -1],\n",
        "                       [1, 0, -1]])\n",
        "\n",
        "kernel_5x5 = np.array([[1, 1, 0, -1, -1],\n",
        "                       [1, 1, 0, -1, -1],\n",
        "                       [1, 1, 0, -1, -1],\n",
        "                       [1, 1, 0, -1, -1],\n",
        "                       [1, 1, 0, -1, -1]])\n",
        "\n",
        "filtered_3x3 = cv2.filter2D(image_rgb, -1, kernel_3x3)\n",
        "filtered_5x5 = cv2.filter2D(image_rgb, -1, kernel_5x5)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(image_rgb)\n",
        "axes[0].set_title(\"Original\")\n",
        "\n",
        "axes[1].imshow(filtered_3x3)\n",
        "axes[1].set_title(\"Filter 3x3 Kernel)\")\n",
        "\n",
        "axes[2].imshow(filtered_5x5)\n",
        "axes[2].set_title(\"Filter (5x5 Kernel)\")\n",
        "\n",
        "for ax in axes:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU0XVl6mI2g7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dhx_1N54N_2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image = cv2.imread('/content/a.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "kernels = {\n",
        "    \"Identity\": np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]], np.float32),\n",
        "    \"Box Blur\": np.ones((3, 3), np.float32) / 9,\n",
        "    \"Gaussian Blur\": cv2.getGaussianKernel(3, 0) * cv2.getGaussianKernel(3, 0).T,\n",
        "    \"Sharpen\": np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32),\n",
        "    \"Edge Detection\": np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], np.float32),\n",
        "    \"Sobel X\": np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32),\n",
        "    \"Sobel Y\": np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (name, kernel) in enumerate(kernels.items()):\n",
        "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
        "    axes[i].imshow(filtered_image, cmap='gray')\n",
        "    axes[i].set_title(name)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kox7syk7cV-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAWUM5mm5jYN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = cv2.imread('/content/a.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "kernels = {\n",
        "    \"Custom Edge Enhance\": np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]], np.float32),\n",
        "    \"Custom Emboss\": np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]], np.float32),\n",
        "    \"Large Gaussian Blur\": cv2.getGaussianKernel(15, 5) * cv2.getGaussianKernel(15, 5).T,\n",
        "}\n",
        "\n",
        "def laplacian_of_gaussian(image):\n",
        "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    return cv2.Laplacian(blurred, cv2.CV_64F)\n",
        "\n",
        "def frequency_filter(image, high_pass=True, radius=30):\n",
        "    dft = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "    dft_shift = np.fft.fftshift(dft)\n",
        "\n",
        "    rows, cols = image.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "    mask = np.ones((rows, cols, 2), np.uint8)\n",
        "    cv2.circle(mask, (ccol, crow), radius, (0, 0), thickness=-1)\n",
        "    if high_pass:\n",
        "        mask = 1 - mask\n",
        "\n",
        "    fshift = dft_shift * mask\n",
        "    f_ishift = np.fft.ifftshift(fshift)\n",
        "    img_back = cv2.idft(f_ishift)\n",
        "    img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
        "    return img_back\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "axes[0].imshow(image, cmap='gray')\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Apply custom kernels\n",
        "for i, (name, kernel) in enumerate(kernels.items(), 1):\n",
        "    filtered_image = cv2.filter2D(image, -1, kernel)\n",
        "    axes[i].imshow(filtered_image, cmap='gray')\n",
        "    axes[i].set_title(name)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Apply Laplacian of Gaussian\n",
        "axes[3].imshow(laplacian_of_gaussian(image), cmap='gray')\n",
        "axes[3].set_title(\"Laplacian of Gaussian\")\n",
        "axes[3].axis('off')\n",
        "\n",
        "# Apply high-pass and low-pass frequency filters\n",
        "axes[4].imshow(frequency_filter(image, high_pass=False), cmap='gray')\n",
        "axes[4].set_title(\"Low-Pass Filter (Frequency)\")\n",
        "axes[4].axis('off')\n",
        "\n",
        "axes[5].imshow(frequency_filter(image, high_pass=True), cmap='gray')\n",
        "axes[5].set_title(\"High-Pass Filter (Frequency)\")\n",
        "axes[5].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGvuoro7Y2xM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFNqKPPuFsCN"
      },
      "source": [
        "## Amaliyot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iTjSJ6zLGVC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3UfB1mndo0J",
        "outputId": "e503cba7-4f69-4fb8-9768-e246e09e8c39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(29, 36, 35)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "animals = [\n",
        "\"Lion\",\"Tiger\",\"Elephant\",\"Giraffe\",\"Zebra\",\"Cheetah\",\"Leopard\",\"Bear\",\"Wolf\",\"Fox\",\n",
        "\"Deer\",\"Rabbit\",\"Kangaroo\",\"Panda\",\"Hippopotamus\",\"Rhinoceros\",\"Monkey\",\"Gorilla\",\"Chimpanzee\",\n",
        "\"Hyena\",\"Bison\",\"Buffalo\",\"Camel\",\"Horse\",\"Sheep\",\"Goat\",\"Dog\",\"Cat\",\"Moose\"\n",
        "]\n",
        "\n",
        "vegetables = [\n",
        "\"Potato\",\"Tomato\",\"Cucumber\",\"Carrot\",\"Onion\",\"Garlic\",\"Pepper\",\"Spinach\",\"Cabbage\",\"Broccoli\",\n",
        "\"Cauliflower\",\"Celery\",\"Lettuce\",\"Pumpkin\",\"Radish\",\"Beetroot\",\"Green Bean\",\"Pea\",\"Eggplant\",\n",
        "\"Zucchini\",\"Corn\",\"Chili\",\"Okra\",\"Ginger\",\"Mushroom\",\"Sweet Potato\",\"Turnip\",\"Leek\",\"Asparagus\",\n",
        "\"Artichoke\",\"Parsnip\",\"Yam\",\"Scallion\",\"Kale\",\"Bok Choy\",\"Brussels Sprout\"\n",
        "]\n",
        "\n",
        "fruits = [\n",
        "\"Apple\",\"Banana\",\"Orange\",\"Grape\",\"Mango\",\"Pineapple\",\"Strawberry\",\"Blueberry\",\"Watermelon\",\n",
        "\"Cherry\",\"Peach\",\"Pear\",\"Plum\",\"Kiwi\",\"Papaya\",\"Lemon\",\"Lime\",\"Apricot\",\"Fig\",\"Pomegranate\",\n",
        "\"Raspberry\",\"Blackberry\",\"Coconut\",\"Lychee\",\"Guava\",\"Mandarin\",\"Tangerine\",\"Dragonfruit\",\n",
        "\"Jackfruit\",\"Durian\",\"Avocado\",\"Grapefruit\",\"Cantaloupe\",\"Cranberry\",\"Mulberry\"\n",
        "]\n",
        "\n",
        "len(animals), len(vegetables), len(fruits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aBB9HHdpAY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8XV-qoBqSDO"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Empty dataframe to store student submissions\n",
        "students_df = pd.DataFrame(columns=[\"Name\", \"Student ID\"])\n",
        "\n",
        "# Function to add student entry\n",
        "def add_student(name, student_id):\n",
        "    global students_df\n",
        "\n",
        "    if name.strip() == \"\":\n",
        "        return students_df, \"‚ùå Name cannot be empty\"\n",
        "\n",
        "    # Add to dataframe\n",
        "    students_df.loc[len(students_df)] = [name, student_id]\n",
        "\n",
        "    return students_df, f\"‚úÖ Added: {name}\"\n",
        "\n",
        "# Function to download CSV\n",
        "def download_csv():\n",
        "    global students_df\n",
        "    file_path = \"students.csv\"\n",
        "    students_df.to_csv(file_path, index=False)\n",
        "    return file_path\n",
        "\n",
        "# UI Layout\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üìù Student Registration Form\")\n",
        "\n",
        "    with gr.Row():\n",
        "        name_input = gr.Textbox(label=\"Student Name\")\n",
        "        id_input = gr.Textbox(label=\"Student ID (optional)\")\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "    status = gr.Textbox(label=\"Status\")\n",
        "\n",
        "    gr.Markdown(\"### üìã Registered Students\")\n",
        "    table = gr.Dataframe(headers=[\"Name\", \"Student ID\"], interactive=False)\n",
        "\n",
        "    download_btn = gr.Button(\"Download CSV\")\n",
        "    file_output = gr.File(label=\"Download Students.csv\")\n",
        "\n",
        "    # Actions\n",
        "    submit_btn.click(add_student, inputs=[name_input, id_input], outputs=[table, status])\n",
        "    download_btn.click(download_csv, outputs=file_output)\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUkeWBu7dpLM"
      },
      "outputs": [],
      "source": [
        "students_df = pd.read_csv(\"/content/students.csv\")\n",
        "students_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OVbzYnkdpfz"
      },
      "outputs": [],
      "source": [
        "# Combine all items\n",
        "import random\n",
        "all_items = animals + vegetables + fruits\n",
        "random.shuffle(all_items)\n",
        "\n",
        "# If fewer items exist, cycle them\n",
        "assignments = (all_items * (len(students_df) // len(all_items) + 1))[:len(students_df)]\n",
        "\n",
        "students_df[\"Assigned_Topic\"] = assignments\n",
        "students_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3HVQOBIiYwD",
        "outputId": "0907dedd-c5ea-408a-c62f-ce792f694bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved as student_topic_assignment.csv\n"
          ]
        }
      ],
      "source": [
        "students_df.to_csv(\"student_topic_assignment.csv\", index=False)\n",
        "print(\"Saved as student_topic_assignment.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6aqqlHVuzoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74WziOK7iZeG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH3IoTFAiZjI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT5apO3CMMKD",
        "outputId": "0747be92-30e9-4966-b205-9c2fe6914d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipped\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/fil.zip\"\n",
        "extract_path = \"/content\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NboAASsdM1hW",
        "outputId": "af23dd2e-0912-42b6-b553-f491cc4340a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LC202310_DavidRioOCWRangers_016_450136_reduced.jpg ‚Üí 11.jpg\n",
            "african-elephant-stands-on-floodplain-watching-camera (1).jpg ‚Üí 12.jpg\n",
            "asian-elephant.jpg ‚Üí 13.jpg\n",
            "cute-little-baby-elephant-mother-600nw-2467644619.jpg ‚Üí 14.jpg\n",
            "iStock-1458791308_523097_reduced.jpg ‚Üí 15.jpg\n",
            "j7u2wtpsm9yjrzumdLYC7k.jpg ‚Üí 16.jpg\n",
            "landscape-view-zoo-where-elephant-walking_665346-11728.jpg ‚Üí 17.jpg\n",
            "large-elephant-herd-walking-in-dust-in-savuti-in-botswana.jpg ‚Üí 18.jpg\n",
            "Renaming complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/fil\"\n",
        "\n",
        "files = sorted([f for f in os.listdir(folder) if f.lower().endswith(\".jpg\")])\n",
        "# file larni yangi nom bilan nomlab olamiz\n",
        "\n",
        "for i, filename in enumerate(files, start=1):\n",
        "    old_path = os.path.join(folder, filename)\n",
        "    new_name = f\"1{i}.jpg\"\n",
        "    new_path = os.path.join(folder, new_name)\n",
        "\n",
        "    os.rename(old_path, new_path)\n",
        "    print(f\"{filename} ‚Üí {new_name}\")\n",
        "\n",
        "print(\"Renaming complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqLT-vxM5jqF"
      },
      "outputs": [],
      "source": [
        "# .jpg bo'lmagan rasmlardan qutilish, o'chirib yuborish\n",
        "import os\n",
        "import glob\n",
        "\n",
        "folder_path = \"/content/fil\"\n",
        "\n",
        "files = glob.glob(os.path.join(folder_path, \"*\"))\n",
        "\n",
        "for file in files:\n",
        "    # lowercase check to avoid \".JPG\" vs \".jpg\" issues\n",
        "    if not file.lower().endswith(\".jpg\"):\n",
        "        print(\"Deleting:\", file)\n",
        "        os.remove(file)\n",
        "\n",
        "print(\"Done! Bizda faqat .jpg rasmlar qoldi.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XacPigUTH-Fz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "# malum razmerli ramlarni saqlab olamiz\n",
        "folder_path = \"/content/fil\"\n",
        "min_width, min_height = 640, 640\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(\".jpg\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            img = Image.open(file_path)\n",
        "            w, h = img.size\n",
        "\n",
        "            if w < min_width or h < min_height:\n",
        "                print(\"Kichik razmerli rasmlar o'chirildi:\", filename)\n",
        "                os.remove(file_path)\n",
        "\n",
        "        except:\n",
        "            print(\" keraksiz fayllar tashlab yuborildi\", filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "erhMaLFrH-Iy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"/content/fil/fil/12.jpg\")\n",
        "cv2_imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xIL1pJVTH-Lt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "# umumiy rasmlarni ko'rib olamiz\n",
        "\n",
        "folder_path = \"/content/fil/fil\"\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(\".jpg\"):\n",
        "        img = cv2.imread(os.path.join(folder_path, filename))\n",
        "        print(\"Bizda bor rasmlar:\", filename)\n",
        "        cv2_imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMPnZkxiH-Pe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "folder_path = \"/content/fil/fil\"\n",
        "new_size = (224, 224)  # typical CNN input size\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(\".jpg\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(file_path)\n",
        "        resized = cv2.resize(img, new_size)\n",
        "        cv2.imwrite(file_path, resized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcsqQVw6CMe8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "folder_path = \"/content/fil/fil\"\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(\".jpg\"):\n",
        "        img = cv2.imread(os.path.join(folder_path, filename))\n",
        "        print(\"Displaying:\", filename)\n",
        "        cv2_imshow(img)\n",
        "        time.sleep(1)  # show for 2 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm8yDI9xCMht"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNFgIK1JlPg2"
      },
      "source": [
        "## Biz model qurish uchun kerakli rasmlarni yig'ib oldik. Endi model yaxshi ishlashligi uchun bu rasmlarni augmentatsiya qilamiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yklckb4aCMkU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFbcpXYUCMnd",
        "outputId": "231ca476-bccc-4f8a-b728-9ca4532c8496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q albumentations==1.3.1 opencv-python-headless==4.7.0.72 pillow torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuIA3MumCMqc"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# 1ta rasm misolida ko'ramiz\n",
        "img_path = \"/content/fil/fil/11.jpg\"\n",
        "img = Image.open(img_path)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original rasm\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yLo_fTRVCMtq"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  horizontal aylantirish\n",
        "flipped = ImageOps.mirror(img)\n",
        "\n",
        "# Ko'rish\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(flipped)\n",
        "plt.title(\"Horizontal Flip\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdvbzmrLCMwa"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# vertical\n",
        "vflipped = ImageOps.flip(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(vflipped)\n",
        "plt.title(\"Vertical Flip\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTXWyfo-mMcv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWHNzZKsmMhc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "angle = random.randint(-45, 45)\n",
        "rotated = img.rotate(angle)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(rotated)\n",
        "plt.title(f\"Rotation: {90}¬∞\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM7pS4U8mMlU"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.RandomCrop(size=(200, 200))\n",
        "\n",
        "cropped = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cropped)\n",
        "plt.title(\"Random Crop\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Q3dgBnmMpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoRWx-H-mMtD"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.ColorJitter(\n",
        "    brightness=0.4,\n",
        "    contrast=0.4,\n",
        "    saturation=0.4,\n",
        "    hue=0.1\n",
        ")\n",
        "\n",
        "jittered = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(jittered)\n",
        "plt.title(\"Color Jitter\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92awnnWfmMxD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy0HbdyPmM1C"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.GaussianBlur(kernel_size=11)\n",
        "\n",
        "blurred = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(blurred)\n",
        "plt.title(\"Gaussian Blur\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOYjYRs1mM5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "atpgq6awmM9g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_np = np.array(img)\n",
        "noise = np.random.normal(0, 25, image_np.shape).astype('int')\n",
        "\n",
        "noisy_image = np.clip(image_np + noise, 0, 255).astype('uint8')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(noisy_image)\n",
        "plt.title(\"Random Noise\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNQjmM8imNBS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTy-oeShmNFG"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.RandomAffine(degrees=0, shear=20)\n",
        "\n",
        "sheared = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(sheared)\n",
        "plt.title(\"Shear\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cZUOahLnRAJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqhtSAIOnREp"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.RandomPerspective(distortion_scale=0.6, p=1.0)\n",
        "\n",
        "warped = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(warped)\n",
        "plt.title(\"Perspective Warp\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk8t6ftQnRKH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdhc_84RnRO0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.ElasticTransform(alpha=400.0, sigma=10.0)\n",
        "\n",
        "elastic = transform(img)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(elastic)\n",
        "plt.title(\"Elastic Transform\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdcsVFrcnRTX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8woxqieznRXv"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = T.RandomErasing(p=1.0, scale=(0.1, 0.3), ratio=(0.3, 3.0))\n",
        "\n",
        "to_tensor = T.ToTensor()\n",
        "to_pil = T.ToPILImage()\n",
        "\n",
        "img_tensor = to_tensor(img)\n",
        "cutout_tensor = transform(img_tensor)\n",
        "cutout_img = to_pil(cutout_tensor)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cutout_img)\n",
        "plt.title(\"Cutout / Random Erasing\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTkLntOnnRcP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzAExbc2nRgr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path2 = \"/content/fil/fil/110.jpg\"    # 2-rasm\n",
        "img2 = Image.open(img_path2).resize(img.size)\n",
        "\n",
        "alpha = 0.4\n",
        "\n",
        "mixup = np.array(img) * alpha + np.array(img2) * (1 - alpha)\n",
        "mixup = mixup.astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"rasm 1\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(img2)\n",
        "plt.title(\"rasm 2\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(mixup)\n",
        "plt.title(\"Mixup\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5i2xTWdnRlV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86fYlyfcnRp6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "img2 = Image.open(\"/content/fil/fil/13.jpg\").resize(img.size)\n",
        "img1_np = np.array(img)\n",
        "img2_np = np.array(img2)\n",
        "\n",
        "h, w, _ = img1_np.shape\n",
        "\n",
        "# random bounding box\n",
        "cut_w, cut_h = w // 3, h // 3\n",
        "x = random.randint(0, w - cut_w)\n",
        "y = random.randint(0, h - cut_h)\n",
        "\n",
        "cutmix = img1_np.copy()\n",
        "cutmix[y:y+cut_h, x:x+cut_w] = img2_np[y:y+cut_h, x:x+cut_w]\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cutmix)\n",
        "plt.title(\"CutMix\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsT1yNvSnRu4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulxpX4rGppqz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
        "equalized = cv2.equalizeHist(img_cv)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_cv, cmap='gray')\n",
        "plt.title(\"Original Grayscale\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(equalized, cmap='gray')\n",
        "plt.title(\"Histogram Equalization\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVAUdy-YppwT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VczdWFQpp2A"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "clahe_img = clahe.apply(img_cv)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_cv, cmap='gray')\n",
        "plt.title(\"Original Grayscale\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(clahe_img, cmap='gray')\n",
        "plt.title(\"CLAHE Result\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2O8yT8lpp67"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uowAhtt4pp_4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kernel = np.array([[0, -1,  0],\n",
        "                   [-1,  5, -1],\n",
        "                   [0, -1,  0]])\n",
        "\n",
        "sharpened = cv2.filter2D(np.array(img), -1, kernel)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(sharpened)\n",
        "plt.title(\"Sharpened Image\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XCIDC-0pqGr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88IQORf8pqRU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "72wZ6mespqWl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "h, w, _ = img_np.shape\n",
        "\n",
        "# fog density\n",
        "fog_density = np.random.uniform(0.3, 0.7)\n",
        "\n",
        "# white fog layer\n",
        "fog = np.full((h, w, 3), 255, dtype=np.float32)\n",
        "\n",
        "# blur fog to look natural\n",
        "fog = cv2.GaussianBlur(fog, (101, 101), 0)\n",
        "\n",
        "foggy = cv2.addWeighted(img_np, 1 - fog_density, fog, fog_density, 0)\n",
        "foggy = foggy.astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_np.astype(np.uint8))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(foggy)\n",
        "plt.title(\"Random Fog\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z44OS9AinRz7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSNp0xFFCMzO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "h, w, _ = img_np.shape\n",
        "rain = img_np.copy()\n",
        "\n",
        "num_drops = int((h * w) * 0.001)  # rain density\n",
        "length = 20                      # drop length\n",
        "\n",
        "for _ in range(num_drops):\n",
        "    x = np.random.randint(0, w)\n",
        "    y = np.random.randint(0, h)\n",
        "    cv2.line(rain, (x, y), (x + np.random.randint(-2, 2), y + length), (200, 200, 200), 1)\n",
        "\n",
        "# blur rain to look natural\n",
        "rain = cv2.blur(rain, (3, 3))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_np.astype(np.uint8))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(rain.astype(np.uint8))\n",
        "plt.title(\"Rain Augmentation\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QOZew0kqRQA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFMXe5UiqRVW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "h, w, _ = img_np.shape\n",
        "snow = img_np.copy()\n",
        "\n",
        "# snow density\n",
        "density = int((h * w) * 0.0015)\n",
        "\n",
        "for _ in range(density):\n",
        "    x = np.random.randint(0, w)\n",
        "    y = np.random.randint(0, h)\n",
        "    radius = np.random.randint(0, 3)\n",
        "    cv2.circle(snow, (x, y), radius, (255, 255, 255), -1)\n",
        "\n",
        "snow = cv2.GaussianBlur(snow, (3, 3), 0)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_np.astype(np.uint8))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(snow.astype(np.uint8))\n",
        "plt.title(\"Snow Augmentation\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4paqyQ8qRa0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0PIgWbvqRgq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "h, w, _ = img_np.shape\n",
        "\n",
        "# Random shadow polygon\n",
        "num_points = np.random.randint(3, 6)\n",
        "points = np.array([\n",
        "    [np.random.randint(0, w), np.random.randint(h//2, h)]\n",
        "    for _ in range(num_points)\n",
        "], dtype=np.int32)\n",
        "\n",
        "shadow_mask = np.zeros_like(img_np, dtype=np.uint8)\n",
        "\n",
        "# fill polygon\n",
        "cv2.fillPoly(shadow_mask, [points], (255, 255, 255))\n",
        "\n",
        "# blur shadow to make it realistic\n",
        "shadow_mask = cv2.GaussianBlur(shadow_mask, (101, 101), 0)\n",
        "\n",
        "alpha = 0.6  # shadow intensity\n",
        "shadow_img = img_np * (1 - alpha * (shadow_mask / 255.0))\n",
        "shadow_img = shadow_img.astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_np.astype(np.uint8))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(shadow_img)\n",
        "plt.title(\"Random Shadow\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvBpceDYqRmi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pzVq6MeLqRrx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter, map_coordinates\n",
        "\n",
        "img_np = np.array(img).astype(np.float32)\n",
        "\n",
        "# Elastic parameters\n",
        "alpha = 40\n",
        "sigma = 6\n",
        "\n",
        "shape = img_np.shape[:2]\n",
        "\n",
        "dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "\n",
        "x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "\n",
        "coords = np.array([y + dy, x + dx])\n",
        "\n",
        "# warp each channel\n",
        "warped = np.zeros_like(img_np)\n",
        "for i in range(3):\n",
        "    warped[:,:,i] = map_coordinates(img_np[:,:,i], coords, order=1)\n",
        "\n",
        "# add noise\n",
        "noise = np.random.normal(0, 10, img_np.shape)\n",
        "warped_noisy = np.clip(warped + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img_np.astype(np.uint8))\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(warped.astype(np.uint8))\n",
        "plt.title(\"Elastic Warp\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(warped_noisy)\n",
        "plt.title(\"Elastic + Noise\")\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvA-qrilqRxD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcA2o-JUqR8O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjiEMKePqSIm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C7Lb_x2qSOA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mKn99-5qSTU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xzCL25AqSYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuBTB_B2qSeM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l73XvYqaqSk1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDiIuB7IqSqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1w2y8IgqSv0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilz2oHIgqS1Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM80iVvaqS7S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFRlkYOuqTA9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOIVT5PMqTHr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "komxeqiqqTNX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}